{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: implement a character RNN model to predict next characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.column_data import *\n",
    "\n",
    "PATH = Path('data/nlp')\n",
    "\n",
    "class RNNLearner(Learner):\n",
    "    def __init__(self, data, models, **kwargs):\n",
    "        super().__init__(data, models, **kwargs)\n",
    "\n",
    "    def _get_crit(self, data): return F.nll_loss\n",
    "\n",
    "    def summary(self): return model_summary(self.model, [torch.ones(3, dtype=torch.int64), torch.ones(3, dtype=torch.int64)])\n",
    "\n",
    "\n",
    "class RNNModel(BasicModel):\n",
    "    def get_layer_groups(self): return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "# text = open(PATH/'nietzsche.txt').read()\n",
    "# print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\x00\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyzÆäæéë'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chars = sorted(list(set(text)))\n",
    "# chars.insert(0,'\\0') # padding chars\n",
    "# n_char = len(chars)\n",
    "# n_char\n",
    "# ''.join(chars[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 578177\n"
     ]
    }
   ],
   "source": [
    "text = open(PATH/'KVH.txt',encoding='utf-8').read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang hai chiếc giường bên cạnh, thấy Quý ròm và nhỏ Hạnh vẫn còn ngủ say sưa, nó biếng nhác nằm ườn thêm một lát .\\n\\nỞ nhà, Tiểu Long không bao giờ như thế . Hễ mở mắt là nó ngồi bật dậy, tót xuống khỏi đi-văng . Cả anh Tuấn và anh Tú cũng vậy . Tác phong con nhà võ bao giờ cũng nhanh gọn lẹ làng .\\n\\nNhưng chiều nay chiếc giường nệm nhà Quý ròm đã níu lưng nó xuống . Đến chơi nhà Quý ròm, thỉnh thoảng Tiểu Long vẫn nằm trên chiếc giường này và lần nào'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "chars.insert(0,'\\0') # padding chars\n",
    "n_char = len(chars)\n",
    "n_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00\\n !\"%()+,-.0123456789:;?ABCDEGHIJKLMNOPQRSTUVXY_abcdefghiklmnopqrstuvwxy°ÀÁÂÊÌÍÐÒÔÚÝàáâãèéêìíòóôõùúýĂăĐđĩũƠơƯưẠạẢảấẦầẩẫậắằẳẵặẹẻẽẾếềỂểễệỉịọỎỏỐốỒồỔổỗộớỜờỞởỡợụỦủứỪừửữựỳỵỷỹ–’“”…'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c:i for i,c in enumerate(chars)}\n",
    "idx2char = {i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 chars models (hard-coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeCharsRNNAdd(nn.Module):\n",
    "    def __init__(self,n_uchars,n_factors,n_hidden):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "        self.w_in = nn.Linear(n_factors,n_hidden)\n",
    "        self.w_hidden= nn.Linear(n_hidden,n_hidden)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)\n",
    "        \n",
    "    def forward(self,c1,c2,c3):\n",
    "        \n",
    "        i1_h = F.relu(self.w_in(self.emb(c1))) #(bs,n_hidden)\n",
    "        \n",
    "        h = V(torch.zeros(i1_h.size()).cuda())\n",
    "        h = h+i1_h # (bs,n_hidden)\n",
    "        h = F.tanh(self.w_hidden(h)) #(bs,n_hidden)\n",
    "        \n",
    "        i2_h = F.relu(self.w_in(self.emb(c2)))\n",
    "        h = F.tanh(self.w_hidden(h+i2_h))\n",
    "        \n",
    "        i3_h = F.relu(self.w_in(self.emb(c3)))\n",
    "        h = F.tanh(self.w_hidden(h+i3_h))\n",
    "        \n",
    "        out = F.log_softmax(self.w_out(h)) # (bs,n_uchars)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578177\n"
     ]
    }
   ],
   "source": [
    "cs=3\n",
    "l = len(text)\n",
    "print(l)\n",
    "c1_idxs = [char2idx[c] for c in text[0:l-cs]]\n",
    "c2_idxs = [char2idx[c] for c in text[1:l-(cs-1)]]\n",
    "c3_idxs = [char2idx[c] for c in text[2:l-(cs-2)]]\n",
    "c4_idxs = [char2idx[c] for c in text[3:l-(cs-3)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc san'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ơng 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang h'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([idx2char[i] for i in c1_idxs[:50]])\n",
    "''.join([idx2char[i] for i in c3_idxs[:50]])\n",
    "''.join([idx2char[i] for i in c4_idxs[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578174,)\n",
      "(578174,)\n",
      "(578174,)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array(c1_idxs)\n",
    "x2 = np.array(c2_idxs)\n",
    "x3 = np.array(c3_idxs)\n",
    "y = np.array(c4_idxs)\n",
    "print(x1.shape)\n",
    "print(x3.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai columnar data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use columnar data model (with loaders) from fast.ai\n",
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, is_reg=False,bs=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Chương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc san'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ơng 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang h'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if data is loaded correctly\n",
    "temp = next(iter(md.trn_dl))\n",
    "len(temp)\n",
    "''.join([idx2char[i] for i in temp[0][:50]])\n",
    "''.join([idx2char[i] for i in temp[1][:50]])\n",
    "''.join([idx2char[i] for i in temp[2][:50]])\n",
    "''.join([idx2char[i] for i in temp[3][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578173"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ơng 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang h'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_y)\n",
    "''.join([idx2char[i] for i in md.trn_y[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeCharsRNNAdd(\n",
       "  (emb): Embedding(174, 87)\n",
       "  (w_in): Linear(in_features=87, out_features=512, bias=True)\n",
       "  (w_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (w_out): Linear(in_features=512, out_features=174, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_factor = n_char//2\n",
    "model = ThreeCharsRNNAdd(n_char,n_factor,512).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low abstract fast.ai fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba7563e39fa4a51b3a85c2f69f1a998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.085446   1.843928  \n",
      "    1      2.135862   3.867795                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.86779])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optim.Adam(model.parameters(), 1e-2)\n",
    "\n",
    "fit(model, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b768cd297a74c4baa4e82d607b317aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.668541   1.034816  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.03482])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-3)\n",
    "fit(model, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher abstract fast.ai Learner class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeCharsRNNAdd(\n",
       "  (emb): Embedding(174, 87)\n",
       "  (w_in): Linear(in_features=87, out_features=256, bias=True)\n",
       "  (w_hidden): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (w_out): Linear(in_features=256, out_features=174, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(to_gpu(model))\n",
    "\n",
    "learner = RNNLearner(md,model,opt_fn=optim.Adam)\n",
    "\n",
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f97faddb6e43aba47eead1c8575c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.811868   2.026871  \n",
      "    1      1.647477   0.615167                                \n",
      "    2      1.623399   0.820811                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.82081])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(1e-2, 1, wds=1e-4, cycle_len=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(model,inp):\n",
    "    idxs = T(np.array([char2idx[c] for c in inp]))\n",
    "    p = model(*V(idxs)) # (bs,n_uchars)\n",
    "    i = np.argmax(to_np(p))\n",
    "    return idx2char[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char(model,'tìn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char(model,'Đan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tình nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Diệp đá nhỏ Di\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tìn'\n",
    "for i in range(200):\n",
    "    sampl+= next_char(model,sampl[-3:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-char models - Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCharsRNNAdd(nn.Module):\n",
    "    def __init__(self,n_uchars,n_factors,n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "        self.w_in = nn.Linear(n_factors,n_hidden)\n",
    "        self.w_hidden= nn.Linear(n_hidden,n_hidden)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)\n",
    "        \n",
    "    def forward(self,*cs):\n",
    "        h = V(torch.zeros((cs[0].size(0), self.n_hidden)).cuda())\n",
    "        for c in cs:\n",
    "            i_h = F.relu(self.w_in(self.emb(c)))\n",
    "            h = h+i_h\n",
    "            h = F.tanh(self.w_hidden(h))\n",
    "        \n",
    "        out = F.log_softmax(self.w_out(h)) # (bs,n_uchars)\n",
    "        return out\n",
    "\n",
    "class NCharsRNNConcat(nn.Module):\n",
    "    def __init__(self,n_uchars,n_factors,n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "        self.w_in = nn.Linear(n_factors+n_hidden,n_hidden)\n",
    "        self.w_hidden= nn.Linear(n_hidden,n_hidden)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)\n",
    "        \n",
    "    def forward(self,*cs):\n",
    "        h = V(torch.zeros((cs[0].size(0), self.n_hidden)).cuda())\n",
    "        for c in cs:\n",
    "            cat = torch.cat((h,self.emb(c)),1)\n",
    "            i_h = F.relu(self.w_in(cat))\n",
    "            h = F.tanh(self.w_hidden(i_h))\n",
    "        \n",
    "        out = F.log_softmax(self.w_out(h),dim=-1) # (bs,n_uchars)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(text)\n",
    "def get_chars_md(cs):\n",
    "    X = []\n",
    "    for i in range(0,cs):\n",
    "        c_idxs = np.array([char2idx[c] for c in text[i:l-(cs-i)]])\n",
    "#         print(c_idxs.shape)\n",
    "        X.append(c_idxs)\n",
    "    X = np.stack(X,axis=1)\n",
    "    print(X.shape)\n",
    "    y= np.array([char2idx[c] for c in text[cs:l]])\n",
    "    print(y.shape)\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578167, 10)\n",
      "(578167,)\n"
     ]
    }
   ],
   "source": [
    "cs=10\n",
    "X,y = get_chars_md(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals=80000\n",
    "val_idxs = np.arange(X.shape[0]-n_vals,X.shape[0])\n",
    "md = ColumnarModelData.from_arrays('.', val_idxs, X, y, is_reg=False,bs=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Chương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc san'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hương 1\\nTiểu Long thức dậy trước tiên .\\n\\nLiếc sang'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'iểu Long thức dậy trước tiên .\\n\\nLiếc sang hai chiế'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if data is loaded correctly\n",
    "temp = next(iter(md.trn_dl))\n",
    "len(temp)\n",
    "''.join([idx2char[i] for i in temp[0][:50]])\n",
    "''.join([idx2char[i] for i in temp[1][:50]])\n",
    "''.join([idx2char[i] for i in temp[cs][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' tục vật nhau với nó, mày sẽ bị đo đất như tao chứ'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'tục vật nhau với nó, mày sẽ bị đo đất như tao chứ '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hau với nó, mày sẽ bị đo đất như tao chứ gì?\\n\\nBất '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = next(iter(md.val_dl))\n",
    "len(temp)\n",
    "''.join([idx2char[i] for i in temp[0][:50]])\n",
    "''.join([idx2char[i] for i in temp[1][:50]])\n",
    "''.join([idx2char[i] for i in temp[cs][:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with hidden layers ADDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCharsRNNAdd(\n",
       "  (emb): Embedding(174, 87)\n",
       "  (w_in): Linear(in_features=87, out_features=512, bias=True)\n",
       "  (w_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (w_out): Linear(in_features=512, out_features=174, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with hidden layers ADDED\n",
    "n_factor = n_char//2\n",
    "model = NCharsRNNAdd(n_char,n_factor,512).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcd07737a184f89afe21d5dd0ec3c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.107023   3.711234  \n",
      "    1      1.900071   2.745398                              \n",
      "    2      1.713712   1.871645                              \n",
      "    3      1.643395   1.705535                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.70553])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(to_gpu(model))\n",
    "\n",
    "learner = RNNLearner(md,model,opt_fn=optim.Adam)\n",
    "\n",
    "learner.fit(1e-2, 1, wds=1e-4, cycle_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab880ea1e024dab8a5844693947082b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.728831   1.80382   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.80382])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opt = optim.Adam(model.parameters(), 1e-2)\n",
    "\n",
    "# fit(model, md, 1, opt, F.nll_loss)\n",
    "# set_lrs(opt, 1e-3)\n",
    "# fit(model, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text from sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ư đá .\\n\\nQuý ròm chép miệng :\\n\\n- Đầu mày cứng như vậy hèn gì học hoài không nhét vô lấy một chữ !\\n\\nLời châm chọc của Quý ròm làm Tiểu Long cụt hứng :\\n\\n- Đừng chơi quê anh em, mày !\\n\\nQuý ròm nhe răng cười :\\n\\n- Chứ mày luyện môn này chi vậy ?\\n\\n- Sao lại chi vậy ? - Tiểu Long hào hứng giải thích - Luyện môn này, đứa nào đánh tao, tao không cần đánh lại, chỉ cần đưa đầu ra đỡ là ...\\n\\n- ... \"Rắc\" một cái, cánh tay địch thủ gãy lìa ! - Quý ròm nhanh nhẩu tiếp lời .\\n\\nTiểu Long nhăn mặt :\\n\\n- Mày lúc nào '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[2000:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ợ'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char(model.model,'chỉ cần đư')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char(model.model,'Mày lúc nà')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chỉ cần được mắt như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế này chuyện như thế \n"
     ]
    }
   ],
   "source": [
    "sampl = 'chỉ cần đư'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model.model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with hidden layer concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCharsRNNConcat(\n",
       "  (emb): Embedding(174, 87)\n",
       "  (w_in): Linear(in_features=599, out_features=512, bias=True)\n",
       "  (w_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (w_out): Linear(in_features=512, out_features=174, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940432d07db44e28b21bdcf5ee9b09c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.869167   9.664738  \n",
      "    1      2.646773   3.560696                              \n",
      "    2      2.056578   2.14612                               \n",
      "    3      1.978247   1.987531                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.98753])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with hidden layers ADDED\n",
    "n_factor = n_char//2\n",
    "model = NCharsRNNConcat(n_char,n_factor,512).cuda()\n",
    "model\n",
    "\n",
    "model = RNNModel(to_gpu(model))\n",
    "\n",
    "learner = RNNLearner(md,model,opt_fn=optim.Adam)\n",
    "\n",
    "learner.fit(1e-2, 1, wds=1e-4, cycle_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150f1aa460ab48cebbf9a4617240641d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.919414   1.953072  \n",
      "    1      1.901525   1.906739                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.90674])]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(1e-3, 1, wds=1e-4, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mày lúc nào chuyện gì thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như \n"
     ]
    }
   ],
   "source": [
    "# text generation\n",
    "sampl = 'Mày lúc nà'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model.model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char RNN from pytorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.RNN:\n",
    "\n",
    "For each element in the input sequence, each layer computes the following\n",
    "function:\n",
    "\n",
    "\n",
    "$$h_t = \\tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})$$\n",
    "\n",
    "where $h_t$ is the hidden state at time t, and $x_t$ is\n",
    "the hidden state of the previous layer at time t-1  or the initial hidden state at time 0.\n",
    "\n",
    "If nonlinearity='relu', then `ReLU` is used instead\n",
    "of `tanh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578171, 6)\n",
      "(578171,)\n"
     ]
    }
   ],
   "source": [
    "cs=6\n",
    "X,y = get_chars_md(cs)\n",
    "\n",
    "n_vals=40000\n",
    "val_idxs = np.arange(X.shape[0]-n_vals,X.shape[0])\n",
    "md = ColumnarModelData.from_arrays('.', val_idxs, X, y, is_reg=False,bs=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self,n_uchars,n_factors,n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "        \n",
    "        # Replace these following 2 lines with pytorch RNN class\n",
    "#         self.w_in = nn.Linear(n_factors,n_hidden)\n",
    "#         self.w_hidden= nn.Linear(n_hidden,n_hidden)\n",
    "        self.rnn = nn.RNN(n_factors,n_hidden)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)\n",
    "        \n",
    "    def forward(self,*cs):\n",
    "        h = V(torch.zeros((1, cs[0].size(0), self.n_hidden)).cuda())\n",
    "#         for c in cs:\n",
    "#             i_h = F.relu(self.w_in(self.emb(c)))\n",
    "#             h = h+i_h\n",
    "#             h = F.tanh(self.w_hidden(h))\n",
    "        inp = self.emb(torch.stack(cs)) # 3d matrix, from (8 chars,bs) to (8,bs,n_fac)\n",
    "        out,h = self.rnn(inp,h) \n",
    "        # outp will give back a growing matrix (all hidden states)\n",
    "        #outp.size() will be (cs, bs, n_hidden)\n",
    "        \n",
    "        return F.log_softmax(self.w_out(out[-1]), dim=-1) # outp[-1] to grab the last tstate matrix(bs,n_uchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (emb): Embedding(174, 87)\n",
       "  (rnn): RNN(87, 512)\n",
       "  (w_out): Linear(in_features=512, out_features=174, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with hidden layers ADDED\n",
    "n_factor = n_char//2\n",
    "model = CharRNN(n_char,n_factor,512).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d6791f52254099ab17860d25c9f5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.874065   2.058615  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.05861])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1d40b3bd0f480da30d6bfd9bb89ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.582391   1.724492  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.72449])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optim.Adam(model.parameters(), 1e-2)\n",
    "\n",
    "fit(model, md, 1, opt, F.nll_loss)\n",
    "set_lrs(opt, 1e-3)\n",
    "fit(model, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4a0c80518a4177ba7a795cd76df288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.551379   1.700512  \n",
      "    1      1.527398   1.686372                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.68637])]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fast.ai learner class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b72e9d27ce04da18e47980bd860aab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.377641   2.598731  \n",
      "    1      2.266762   2.613416                                \n",
      "    2      2.150789   2.18908                                 \n",
      "    3      2.07715    2.130686                                \n",
      "    4      1.98244    1.998532                                \n",
      "    5      1.913213   1.95871                                 \n",
      "    6      1.837456   1.872549                                \n",
      "    7      1.787472   1.813219                                \n",
      "    8      1.756168   1.781808                                \n",
      "    9      1.763692   1.801813                                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.80181])]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel(to_gpu(model))\n",
    "\n",
    "learner = RNNLearner(md,model,opt_fn=optim.Adam)\n",
    "\n",
    "learner.fit(1e-2, 1, wds=1e-4, cycle_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = learner.predict()\n",
    "pred=np.argmax(pred_log,axis=1)\n",
    "\n",
    "pred_text = ''.join([idx2char[idx] for idx in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c chhàn ciợng cai t chong chư chấ ca chhe càichong chn thn tum cài chch cuanhthm chom ca  cha cộnh  \\nThỏng càn thy chông ca ca càn thou ch thhe chấy chưng cài choih ch cha cng chông  Thểug ciờn ci ch  ch  cuống chu tiy cội càc cột chư Hạn  \\nTi càn thou ci thô  chong chm chả   càn thou cội cuan cào chư chong chhàc cangtuý ròm \\n\\n- Tồiciợc cai \\n\\nTồi ch chô chưc cài \\n\\n- Tay ciờ chấ chchcan ti caết chi cà chn tho  cai chn tii cai cho ci \\n\\nT T  \\nTa cin nho ca gtà htit ciu  Thhy chong càc ci cangtho cộốngtai càn thou caết ca  chưên cà thoyện thưng chông cin chy ci ch hti  cộ cộệng  Thư Hạnh cho ci  cột chưn tuanh \\n\\n- Ta can tà cai ca \\n\\n- T  \\nT Thư can t ciu chấ \\n\\n- Tuocàm  \\nT Thì can tin tiu cà ti choi cài cng can tiy cờ \\nTàn thou cit ciu \\n\\n- T  Thưng chi chng cat tà chư cai \\nT Tồi ch ch  chưncuốnciai c Tàychchcan thng chn tà ti  \\nTiìy chông chn th ti chy tho cingtuý ròm cing chon cng cha càn thou cai càc chi chyngta ch g  \\nTêc cat taa choế cho  chư Hạnh chn tho cho cà chảa cháncaến chấcthhyệ'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ở ngoài đường hơn ở trong nhà thì ba nghĩ vợ chồng con nên xem lại cách quan tâm chăm sóc của mình.\\n\\nNhưng lần này không rõ ba Văn Châu có nghe thấy những lời trách cứ của ông không. Tiếng giày gõ cồm cộp xuống nền đất mỗi lúc một nhỏ dần.\\n\\nBa Văn Châu đi khỏi chừng năm phút, Văn Châu mới quay vào nhà trong ngoắc bọn Quý ròm:\\n\\n- Ra được rồi!\\n\\nRồi nó khẽ nhún vai:\\n\\n- Bây giờ thì các bạn đã biết tôi là con trai hay con gái rồi chứ gì?\\n\\n- Ừ.\\n\\nBa đứa trẻ bẽn lẽn gật đầu. Ngay trong lúc đó bọn trẻ muốn hỏi Văn Châu biết bao nhiêu là chuyện nhưng không đứa nào đủ cản đảm mở miệng. Nhỏ Hạnh chỉ đảo mắt nhìn quanh:\\n\\n- Ba bạn về rồi hả?\\n\\n- Ừ.\\n\\n- Nhà bạn ở đâu thế?\\n\\n- Xa lắm.\\n\\n- Thế bạn đến đây là để chơi với ông bạn đấy ư?\\n\\nVăn Châu gật đầu:\\n\\n- Ừ. Nhưng tôi cũng sắp về nhà rồi. - Rồi nó nói như xua đuổi - Mà các bạn cũng nên về đi.\\n\\nThấy không còn cớ gì nấn ná, bọn Quý ròm đành chào ông của Văn Châu rồi lục tục tuôn ra cổng.\\n\\nLúc sắp sửa chia tay, nhỏ Hạnh còn chỉ tay về phía toà biệt thự nguy '"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_text = ''.join([idx2char[idx] for idx in md.val_ds.y])\n",
    "true_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for characters' names,(sometime they are still wrong), this model is absolutely terrible at generating Vietnamese text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate text from sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiểu Long nghe thằng nhóc cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sampl = 'Tiểu Long'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .\n",
      "\n",
      "Quý Rò và như thế này thằng nhóc cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó cho nó\n"
     ]
    }
   ],
   "source": [
    "sampl = ' .\\n\\nQuý R'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi label output / LSTM / GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been running the model on some amount of chars and predicting the next one. We will repeat the process, but we run the model on n(th) characters and predict (n+1)th characters, i.e see 1st, predict 2nd then see 2nd, predict 3rd ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578166, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char2idx[c] for c in text]\n",
    "cs=10\n",
    "\n",
    "c_dat = [idx[i:i+cs] for i in range(len(idx)-cs)]\n",
    "c_in_dat = c_dat[:-1]\n",
    "c_out_dat = c_dat[1:]\n",
    "\n",
    "X1 = np.stack(c_in_dat)\n",
    "y1 = np.stack(c_out_dat)\n",
    "X1.shape\n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 27,  56, 110, 108,  61,  55,   2,  13,   1,  43],\n",
       "       [ 56, 110, 108,  61,  55,   2,  13,   1,  43,  57],\n",
       "       [110, 108,  61,  55,   2,  13,   1,  43,  57, 133],\n",
       "       [108,  61,  55,   2,  13,   1,  43,  57, 133,  68],\n",
       "       [ 61,  55,   2,  13,   1,  43,  57, 133,  68,   2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56, 110, 108,  61,  55,   2,  13,   1,  43,  57],\n",
       "       [110, 108,  61,  55,   2,  13,   1,  43,  57, 133],\n",
       "       [108,  61,  55,   2,  13,   1,  43,  57, 133,  68],\n",
       "       [ 61,  55,   2,  13,   1,  43,  57, 133,  68,   2],\n",
       "       [ 55,   2,  13,   1,  43,  57, 133,  68,   2,  35]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57817, 10)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(57817, 10)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try non-overlap set of characters\n",
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(text)-cs-1, cs)]\n",
    "\n",
    "# labels: exact same thing, offset by 1\n",
    "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]\n",
    "\n",
    "X2 = np.stack(c_in_dat)\n",
    "y2 = np.stack(c_out_dat)\n",
    "X2.shape\n",
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 27,  56, 110, 108,  61,  55,   2,  13,   1,  43],\n",
       "       [ 57, 133,  68,   2,  35,  62,  61,  55,   2,  67],\n",
       "       [ 56, 159,  51,   2,  52, 120,  72,   2,  67,  65],\n",
       "       [110, 149,  51,   2,  67,  57,  91,  61,   2,  11],\n",
       "       [  1,   1,  35,  57, 130,  51,   2,  66,  49,  61]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56, 110, 108,  61,  55,   2,  13,   1,  43,  57],\n",
       "       [133,  68,   2,  35,  62,  61,  55,   2,  67,  56],\n",
       "       [159,  51,   2,  52, 120,  72,   2,  67,  65, 110],\n",
       "       [149,  51,   2,  67,  57,  91,  61,   2,  11,   1],\n",
       "       [  1,  35,  57, 130,  51,   2,  66,  49,  61,  55]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRNN(nn.Module):\n",
    "    def __init__(self,n_uchars,n_factors,n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "\n",
    "        self.rnn = nn.RNN(n_factors,n_hidden)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)\n",
    "        \n",
    "    def forward(self,*cs):\n",
    "#         h = V(torch.zeros((1, cs[0].size(0), self.n_hidden)).cuda())\n",
    "        h = V(torch.zeros((1, cs[0].size(0), self.n_hidden)))\n",
    "\n",
    "        inp = self.emb(torch.stack(cs)) # 3d matrix, from (8 chars,bs) to (8,bs,n_fac)\n",
    "        out,h = self.rnn(inp,h) \n",
    "        # outp will give back a growing matrix (all hidden states)\n",
    "        #outp.size() will be (cs, bs, n_hidden)\n",
    "        \n",
    "        return F.log_softmax(self.w_out(out), dim=-1) #(cs,bs,hidden) to (cs,bs,n_uchars)\n",
    "    \n",
    "# note that we use outp to get all n-char state matrices (cs,bs,n_hidden) instead of outp[-1], \n",
    "# and get output (blue arrow) for each state matrix h and get negative log loss for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for multiple output RNN\n",
    "def nll_loss_seq(inp, targ):\n",
    "    #sl is cs (i.e 10)\n",
    "    #bs is batch size\n",
    "    #n_uchars is number of unique character\n",
    "    #inp size is (cs,bs,n_uchars)\n",
    "\n",
    "    sl,bs,n_uchars = inp.size() \n",
    "    #targ size (yt) is (bs,cs)\n",
    "    #'transpose': change targ to (cs,bs),then flatten it to (cs x bs)\n",
    "    # add 'contiguous' to make sure it really tranposes.\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    \n",
    "    #change inp to (cs x bs,n_uchars)\n",
    "    return F.nll_loss(inp.view(-1,n_uchars), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_char\n",
    "\n",
    "# Model with hidden layers ADDED\n",
    "n_factor = n_char//2\n",
    "# model = CharSeqRNN(n_char,n_factor,512).cuda()\n",
    "model = CharSeqRNN(n_char,n_factor,512)\n",
    "model\n",
    "\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap chars data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals=50000\n",
    "val_idxs = np.arange(X1.shape[0]-n_vals,X1.shape[0])\n",
    "md = ColumnarModelData.from_arrays('.', val_idxs, X1, y1, is_reg=False,bs=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67206013cc9d4311a881e1b809cab49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.926155   1.979435  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.97943])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cbe394f0c14c2da2595a974526209a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.65945    1.717063  \n",
      "    1      1.639788   1.698863                                \n",
      "    2      1.62261    1.68468                                 \n",
      "    3      1.606875   1.674842                                \n",
      "    4      1.592945   1.666674                                \n",
      "    5      1.581559   1.660839                                \n",
      "    6      1.570719   1.655175                                \n",
      "    7      1.560939   1.65209                                 \n",
      "    8      1.552154   1.648335                                \n",
      "    9      1.544639   1.645312                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.64531])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-3)\n",
    "fit(model, md, 10, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(model,inp):\n",
    "    idxs = T(np.array([char2idx[c] for c in inp]))\n",
    "    p = model(*V(idxs))[-1]\n",
    "    i = np.argmax(to_np(p))\n",
    "    return idx2char[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhỏ Hạnh chỉ thấy nó chỉ theo dõi ngay từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ t\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tụi nhỏ '\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhóc nhìn vào nhà Quý ròm nhún và chân theo dõi ngay từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tụi nhóc'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quý ròm đã biết như thế nào cũng chẳng biết được nhỏ Hạnh chỉ thấy nó chỉ theo dõi ngay từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ \n"
     ]
    }
   ],
   "source": [
    "sampl = 'Quý ròm'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiểu Long và Quý ròm nhún và chân theo dõi ngay từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ từ \n"
     ]
    }
   ],
   "source": [
    "sampl = 'Tiểu Long'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model actually does a better job now, as with 3 different samples it generates different and somewhat understandable words (up to 'từ từ'). In fact, this is a Vietnamese word and model got caught in a loop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_i = iter(md.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict: \n",
      "uý ròm màp tức lhinta chỏi nhi ngn nừ niomhân nin thng caợt đhìo \n",
      "\n",
      "Nh nọ đangran nặn nheo dê la  nam cồt nên nà phía sìc niợng \n",
      "Nóưng cừa đhe tau ta  nin tuý ròm mửnt mgiy tâ g cạn thô nhấy Văn Châu ring nonlắ lhi  tể chẳng niohàp  thườc nặt cáih ch g cẽc nh  cgaĩ  \n",
      "\n",
      "Nừn Châu đing chan  chỉn nhưn tào nhn như chỏ Hhm nựu mh g thn thông thêng they nên tuý ròm  nóỏng câ sừy? nhế nưa ngo caa nàp nừn cáp thì h chì h tgư tộốn tàt ra đhỏi ning nhhc \n",
      "\n",
      "Nhông ti nảo ni  Qh bọ mọt tứt tat rầu têi  Qhấy thì\n",
      "\n",
      "True: \n",
      "uý ròm lập tức nhô ra khỏi chỗ nấp và ba chân bốn cẳng rượt theo.\n",
      "\n",
      "Cả ba rón rén men theo bờ rao rậm rạp lần về phía góc đường. Nhưng vừa thò đầu ra, bọn Quý ròm suýt nhảy dựng lên khi thấy Văn Châu đứng lù lù cách đó chừng ba mét, trước một cánh cổng sắt cao nghễu.\n",
      "\n",
      "Văn Châu đang kiễng chân nhìn vào căn nhà nhỏ nằm sau cổng nên không trông thấy bọn Quý ròm, nhưng dù vậy, tim đứa nào đứa nấy vẫn đập thình thịch như muốn vọt ra khỏi đang ngực.\n",
      "\n",
      "Không ai bảo ai, cả ba hấp tấp rụt đầu lại, thấp thỏ\n",
      "----------\n",
      "\n",
      "Predict: \n",
      "ữm tm ni  \n",
      "- Cận Châu rỏ?\n",
      "- Qiểng cột cgaời hhả ng nừig lên tin thưng ning lao n Nii VhiuHàt chút \n",
      "\n",
      "-úc mau  Qh chếng lnnhôảimhu lê h chih tàothếng rhch ch g chônnưn tat tên \n",
      "Nà nhếpg rhỉuciùc \n",
      "\n",
      "- Nm cừ  ná \n",
      "\n",
      "Nhi nói  nưng lào nàc năn Châu rài nhạn  Qhông ciểu tì th  th   Qá chng chìng tii tá càineấ vua nhô n Qhe nào nà cuý ròm nỗng chin  a  đột chếng chàcgi tat \n",
      "\n",
      "-u chấng nhông thô n ni lht chiên thông tàc mhii nhy hăn Châu \n",
      "Nàa nht nhưn tânh ciớc rua đo g  nó cing nàng vhhời thỏn và phu nic na\n",
      "\n",
      "True: \n",
      "ùm em đi!\n",
      "\n",
      "- Văn Châu hả! - Tiếng một người phụ nữ vang lên bên trong hàng rào - Đợi chị một chút.\n",
      "\n",
      "Lát sau, có tiếng ổ khoá kêu lách cách và tiếng cánh cổng khô dầu rít lên. Và tiếng chị Thắm:\n",
      "\n",
      "- Em vào đi!\n",
      "\n",
      "Khổ nỗi, đúng vào lúc Văn Châu dợm chân, không hiểu do cảm cúm, do căng thẳng hay do ma xui quỷ khiến thế nào mà Quý ròm bỗng \"hắt-xì\" một tiếng to như sấm.\n",
      "\n",
      "Âm thanh khủng khiếp đó tất nhiên không lọt khỏi tai Văn Châu. Vừa cất chân định bước qua cổng, nó bỗng sững người nhìn về chỗ góc rà\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "show=2\n",
    "for batch in md_i:\n",
    "    if show==0: break\n",
    "    batch_pred = model(*V(batch[:cs]))[-1] # get 10th char prediction only \n",
    "    batch_pred = np.argmax(to_np(batch_pred),axis=1)\n",
    "    print('\\nPredict: ')\n",
    "    print(''.join(idx2char[i] for i in batch_pred[:500]))\n",
    "    \n",
    "    truth = to_np(batch[cs])[:,-1] # match with 10th char pred above\n",
    "    print('\\nTrue: ')\n",
    "    print(''.join(idx2char[i] for i in truth[:500]))\n",
    "    print('-'*10)\n",
    "    show-=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-overlap char data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharSeqRNN(\n",
       "  (emb): Embedding(174, 87)\n",
       "  (rnn): RNN(87, 512)\n",
       "  (w_out): Linear(in_features=512, out_features=174, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CharSeqRNN(n_char,n_factor,512).cuda()\n",
    "model\n",
    "\n",
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57817, 10)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(57817, 10)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape\n",
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals=8000\n",
    "val_idxs = np.arange(X2.shape[0]-n_vals,X2.shape[0])\n",
    "md = ColumnarModelData.from_arrays('.', val_idxs, X2, y2, is_reg=False,bs=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b6bddc510144c4b1e54ef3c4681f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      2.405729   2.149568  \n",
      "    1      2.043233   1.977288                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.97729])]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 2, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574dfaa591324f9d89043c53ccded6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      1.883453   1.90987   \n",
      "    1      1.829624   1.870148                            \n",
      "    2      1.786403   1.844538                            \n",
      "    3      1.752143   1.825393                            \n",
      "    4      1.723863   1.809057                            \n",
      "    5      1.699202   1.795843                            \n",
      "    6      1.676934   1.785109                            \n",
      "    7      1.656508   1.776136                            \n",
      "    8      1.637628   1.768822                            \n",
      "    9      1.619993   1.763129                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.76313])]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-3)\n",
    "fit(model, md, 10, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05de1287a3814f73ace5954d66f79fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      1.600664   1.758776  \n",
      "    1      1.586842   1.755373                            \n",
      "    2      1.572191   1.752746                            \n",
      "    3      1.557761   1.750838                            \n",
      "    4      1.543799   1.749506                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.74951])]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 5, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhỏ Hạnh nhau thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như t\n"
     ]
    }
   ],
   "source": [
    "## Generating text\n",
    "\n",
    "sampl = 'tụi nhỏ '\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc nh\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tụi nhóc'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quý ròm đã thấy nhỏ Diệp chẳng biết thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì t\n"
     ]
    }
   ],
   "source": [
    "sampl = 'Quý ròm'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiểu Long chẳng biết thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế này thì thằng nhóc như thế\n"
     ]
    }
   ],
   "source": [
    "sampl = 'Tiểu Long'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden matrix initialization\n",
    "\n",
    "Recall that the hidden-to-hidden layer transformation (orange transformation) is telling us the best way to transform the information from the prior state before combining it with the new transformed input. It's reasonable to assume that a good place to start in this transformation is to do nothing. This means we can initiate $w_{hh}$ to be an identity  matrix so that $w_{hh} * h_{(t-1)} = h_{(t-1)}$ : Values of initial state matrix at time t=0 is itself, which contains 0s\n",
    "\n",
    "$$h_t = \\tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})$$\n",
    "\n",
    "\n",
    "This is a trick in long term dependencies in RNN to avoid vanishing and exploding gradients (beside using LSTM or GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_char\n",
    "\n",
    "# Model with hidden layers ADDED\n",
    "n_factor = n_char//2\n",
    "# model = CharSeqRNN(n_char,n_factor,512).cuda()\n",
    "model = CharSeqRNN(n_char,n_factor,512)\n",
    "model\n",
    "\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.FloatTensor of size 512x512]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn.weight_hh_l0.data.copy_(torch.eye(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vals=50000\n",
    "val_idxs = np.arange(X1.shape[0]-n_vals,X1.shape[0])\n",
    "md = ColumnarModelData.from_arrays('.', val_idxs, X1, y1, is_reg=False,bs=512,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621a01c8962b4ac8b44cc765d231656d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      1.915756   1.9568    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.9568])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fbf74657994c32afafd250a7a7bf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      1.671579   1.718789  \n",
      "    1      1.65212    1.702151                                                 \n",
      "    2      1.635029   1.691524                                                 \n",
      "    3      1.619829   1.681655                                                 \n",
      "    4      1.605569   1.674127                                                 \n",
      "    5      1.593565   1.668108                                                 \n",
      "    6      1.583343   1.663394                                                 \n",
      "    7      1.574013   1.660133                                                 \n",
      "    8      1.566405   1.656748                                                 \n",
      "    9      1.558653   1.65411                                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.65411])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-3)\n",
    "fit(model, md, 10, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(model,inp):\n",
    "    idxs = T(np.array([char2idx[c] for c in inp]))\n",
    "    p = model(*V(idxs))[-1]\n",
    "    i = np.argmax(to_np(p))\n",
    "    return idx2char[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhỏ Hạnh như thế nào chỉ chuyện gì chỉ chân chân thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tụi nhỏ '\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhóc dù biết được thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì th\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tụi nhóc'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quý ròm như thế nào chỉ chuyện gì chỉ chân chân thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì\n"
     ]
    }
   ],
   "source": [
    "sampl = 'Quý ròm'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiểu Long và nhỏ Hạnh như thế nào chỉ chuyện gì chỉ chân chân thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì thì\n"
     ]
    }
   ],
   "source": [
    "sampl = 'Tiểu Long'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-cs:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_i = iter(md.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict: \n",
      " thìc tan tuý ròm nêp thc thì na đhôi nhu bhy tà ni chỉn cạn thng taợc theo \n",
      "\n",
      "-h bả cangnan nìm thìo ci ba  cam cai cạn nà nhía tìc tượng \n",
      "Vóưng làa thì tưu ta  nan tuý ròm nẽýt thưy tâ g tên thi nhìy Văn Châu tộng tàntànthc  ti lhung tiomàt  Qhườc mặt cáih th g cẽp nho nhhi  \n",
      "\n",
      "-ừn Châu lộng nham  chân tgưn vào nhngnhư tóỏ Hhm cao lh g chn thông thưng thấy Vạn tuý ròm  nóỏ g ná cừy? nhế tưn ngo cưa ngy càn cưp thì h thì h Vhư tộốn càt ma chôi ning thhc \n",
      "\n",
      "-hing ti cảo mi  nh bi cap thm cat tưu tê\n",
      "\n",
      "True: \n",
      " thự, bọn Quý ròm lập tức nhô ra khỏi chỗ nấp và ba chân bốn cẳng rượt theo.\n",
      "\n",
      "Cả ba rón rén men theo bờ rao rậm rạp lần về phía góc đường. Nhưng vừa thò đầu ra, bọn Quý ròm suýt nhảy dựng lên khi thấy Văn Châu đứng lù lù cách đó chừng ba mét, trước một cánh cổng sắt cao nghễu.\n",
      "\n",
      "Văn Châu đang kiễng chân nhìn vào căn nhà nhỏ nằm sau cổng nên không trông thấy bọn Quý ròm, nhưng dù vậy, tim đứa nào đứa nấy vẫn đập thình thịch như muốn vọt ra khỏi đang ngực.\n",
      "\n",
      "Không ai bảo ai, cả ba hấp tấp rụt đầu lạ\n",
      "----------\n",
      "\n",
      "Predict: \n",
      " -à chng ciọm cm tã \n",
      "\n",
      "- Cận Châu tỏ? - Qiểng bột cgười thâctgabàig tàn tin thưng ting cao n Câi thuubàt cáút \n",
      "\n",
      "-úc nuu  nh thếng b mhôaihhu lêo  thi  tà nhếng chih ch g chôncưn tac mên \n",
      "-ă chếng châuciùn \n",
      "\n",
      "- Cm cà  nã \n",
      "\n",
      "-hi thi  ning cừ  nêc năn Châu tõ  thin  Qhông tiểu rì th  th   nà lhng chìng tỏi cá làymeố vua thi n Qhấ nào càycuý ròm ning ctit bôn cắt thếng chàthư tat \n",
      "\n",
      "Nu nhình nhing lhô n tã lhm cgìên nhông tàc rhii nhy năn Châu \n",
      "-àa nht chân cưnh tiớc ruaythng  nó cỗng cẽng thhời thàn tà\n",
      "\n",
      "True: \n",
      " Mở cổng giùm em đi!\n",
      "\n",
      "- Văn Châu hả! - Tiếng một người phụ nữ vang lên bên trong hàng rào - Đợi chị một chút.\n",
      "\n",
      "Lát sau, có tiếng ổ khoá kêu lách cách và tiếng cánh cổng khô dầu rít lên. Và tiếng chị Thắm:\n",
      "\n",
      "- Em vào đi!\n",
      "\n",
      "Khổ nỗi, đúng vào lúc Văn Châu dợm chân, không hiểu do cảm cúm, do căng thẳng hay do ma xui quỷ khiến thế nào mà Quý ròm bỗng \"hắt-xì\" một tiếng to như sấm.\n",
      "\n",
      "Âm thanh khủng khiếp đó tất nhiên không lọt khỏi tai Văn Châu. Vừa cất chân định bước qua cổng, nó bỗng sững người nhìn về\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "show=2\n",
    "for batch in md_i:\n",
    "    if show==0: break\n",
    "    batch_pred = model(*V(batch[:cs]))[-1] # get 10th char prediction only \n",
    "    batch_pred = np.argmax(to_np(batch_pred),axis=1)\n",
    "    print('\\nPredict: ')\n",
    "    print(''.join(idx2char[i] for i in batch_pred[:500]))\n",
    "    \n",
    "    truth = to_np(batch[cs])[:,-1] # match with 10th char pred above\n",
    "    print('\\nTrue: ')\n",
    "    print(''.join(idx2char[i] for i in truth[:500]))\n",
    "    print('-'*10)\n",
    "    show-=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRNN(nn.Module):\n",
    "    def __init__(self,n_uchars,n_factors,n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "\n",
    "        self.rnn = nn.RNN(n_factors,n_hidden)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)        \n",
    "    def forward(self,*cs):\n",
    "        h = V(torch.zeros((1, cs[0].size(0), self.n_hidden)))\n",
    "\n",
    "        inp = self.emb(torch.stack(cs)) # 3d matrix, from (8 chars,bs) to (8,bs,n_fac)\n",
    "        out,h = self.rnn(inp,h) \n",
    "        # outp will give back a growing matrix (all hidden states)\n",
    "        #outp.size() will be (cs, bs, n_hidden)       \n",
    "        return F.log_softmax(self.w_out(out), dim=-1) #(cs,bs,hidden) to (cs,bs,n_uchars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at our model above, at each forward pass we reset hidden state matrix h. Instead of discarding h, we will keep it and initiate next batch's h with it. However, this requires the dataset to be constructed in a particular way. We will use fastai library to prepare the data. \n",
    "\n",
    "TODO: fastai has a new module called fastai.text which replaces the torchtext library. Replace code above with this new library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRNN(nn.Module):\n",
    "    def __init__(self, n_uchars, n_factors, bs, n_hidden):       \n",
    "        super().__init__()\n",
    "        self.n_uchars = n_uchars\n",
    "        self.n_hidden = n_hidden\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "        self.rnn = nn.RNN(n_factors,n_hidden)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)        \n",
    "        self.init_hidden(bs) #initiate state matrix h here\n",
    "        \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, self.n_hidden))\n",
    "\n",
    "    def forward(self, cs):\n",
    "    # actual shape of cs: torch variable with shape (bptt oscillating, bs)\n",
    "        bs = cs[0].size(0)\n",
    "\n",
    "        # self.h.size(1) might be different from bs (reminder: h.size is (1,bs,n_hidden)\n",
    "        # # as our last batch contains a lessser number of rows\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        inp = self.emb(cs)\n",
    "        outp,h = self.rnn(inp, self.h)\n",
    "        \n",
    "        #def repackage_var(h):\n",
    "            # return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n",
    "        # take data from h and create a new variable from that\n",
    "        # purpose: to remove the 'history of operation' from h variable\n",
    "        # we won't backprop each value of h 'all the way'. \n",
    "        # Only backprop the current value of h and ignore all previous value of h\n",
    "        # This will prevent backprop through too many value of h ('too many layers') -> exploding gradients. \n",
    "        # The method of throwing history of operations away is also called 'Backprop through time' (BPTT)\n",
    "        self.h = repackage_var(h)\n",
    "        \n",
    "        # Important note: result from pytorch ‘forward’ should NOT be a rank 3 tensor. \n",
    "        # It should be 2d tensor so pytorch loss function can work\n",
    "        # thus, we have to convert result from blue matrix with shape (bptt or cs, bs,n_uchars) to\n",
    "        # (bptt x bs, n_uchars). Only this can make pytorch loss function ( F.nll_loss(pred,targ) ) work \n",
    "        #also note that output of ‘forward’ is our prediction. \n",
    "        # For targ, its shape should already be (bptt x bs). Torchtext does this automatically for us. See example below.\n",
    "        # also, pytorch .3 requires dim=-1 to tell which axis soft_max is calculated. In this case it’s vocab_size\n",
    "        return F.log_softmax(self.w_out(outp), dim=-1).view(-1, self.n_uchars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data (torchtext bptt are non-overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/nlp/'\n",
    "\n",
    "TRN_PATH = 'kvh_trn/'\n",
    "VAL_PATH = 'kvh_val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "# !mkdir -p {TRN}\n",
    "# !mkdir -p {VAL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578177"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{TRN}trn.txt', 'w',encoding='utf-8') as text_file:\n",
    "    text_file.write(text[:500000])\n",
    "    \n",
    "with open(f'{VAL}val.txt', 'w',encoding='utf-8') as text_file:\n",
    "    text_file.write(text[500000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 115, 1, 489166)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=10; n_fac=87; n_hidden=512\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data model loader. You can see bptt changing around the original bptt 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([8, 64]), torch.Size([512]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data model\n",
    "it = iter(md.trn_dl)\n",
    "batch = next(it)\n",
    "len(batch), batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([6, 64]), torch.Size([384]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "len(batch), batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([5, 64]), torch.Size([320]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "len(batch), batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([15, 64]), torch.Size([960]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "len(batch), batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 12 \n",
       "   35    35     2     4    48     2    21     6    33    26    10     2     3\n",
       "    3     3    18    52     2     4     2     2    11     9    68    33     6\n",
       "\n",
       "Columns 13 to 25 \n",
       "   20    10     2    10     9     2    69    57    51    11    18    18     5\n",
       "   38     2     3     2    15    12     2     8     2     2    66    15    20\n",
       "\n",
       "Columns 26 to 38 \n",
       "   83    40     2    13     2    22    13    16    28     2     4     5    10\n",
       "    3     7     9     2    77     4     2    20     2     4    10    10     7\n",
       "\n",
       "Columns 39 to 51 \n",
       "   27     4     5    34    76    14     3     2     8     6    30     5     8\n",
       "    3    50    76    62     3    41     6     5     2     2    29     4     4\n",
       "\n",
       "Columns 52 to 63 \n",
       "   10     2    20     2    87     8     7     3     6    30    17     6\n",
       "    2     9    62    22    29     2     2     6     4     3     2     2\n",
       "[torch.LongTensor of size 2x64]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][:2][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  3\n",
       "  3\n",
       " 18\n",
       " 52\n",
       "  2\n",
       "  4\n",
       "  2\n",
       "  2\n",
       " 11\n",
       "  9\n",
       " 68\n",
       " 33\n",
       "  6\n",
       "[torch.LongTensor of size 13]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharSeqStatefulRNN(md.nt, n_fac, bs,n_hidden)\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f766a0b4c428881e63963f08cbce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      2.114959   2.118349  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.11835])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2daef88b664ab5a528a9fb76446d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      1.77288    1.808022  \n",
      "    1      1.740969   1.771976                                                 \n",
      "    2      1.715852   1.760767                                                 \n",
      "    3      1.68967    1.751735                                                 \n",
      "    4      1.688667   1.74174                                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.74174])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-3)\n",
    "fit(model, md, 5, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339596bfb7444fcfba1ba8cc0d603959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      1.628355   1.701124  \n",
      "    1      1.621644   1.69568                                                  \n",
      "    2      1.617894   1.695362                                                 \n",
      "    3      1.620689   1.690939                                                 \n",
      "    4      1.616665   1.69064                                                  \n",
      "    5      1.611596   1.687842                                                 \n",
      "    6      1.610631   1.683048                                                 \n",
      "    7      1.60494    1.683119                                                 \n",
      "    8      1.610443   1.682568                                                 \n",
      "    9      1.597849   1.681767                                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.68177])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "fit(model, md, 10, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = TEXT.numericalize('tụi nhỏ ',device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    5    74     7     2     3     4    45     2\n",
       "[torch.LongTensor of size 1x8]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model(V(idxs.transpose(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 115])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(model,inp):\n",
    "    idxs = TEXT.numericalize(inp,device=-1)\n",
    "    p = model(V(idxs.transpose(0,1)))[-1]\n",
    "    i = np.argmax(to_np(p))\n",
    "    return TEXT.vocab.itos[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ hạnh thì nhỏ h\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tụi nhỏ '\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-bptt:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vợ chồng là thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như \n"
     ]
    }
   ],
   "source": [
    "sampl = 'vợ chồng'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-bptt:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiểu Long như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như thế như\n"
     ]
    }
   ],
   "source": [
    "sampl = 'Tiểu Long'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-bptt:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to actual replace the orange hidden-to-hidden looped with a neural network that decides how much of the state matrix to keep/use at each activation. \n",
    "\n",
    "By having this neural network which controls how much state to use, it learns how to avoid gradient explosions and create an effective sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqLSTMRNN(nn.Module):\n",
    "    def __init__(self, n_uchars, n_factors, bs, n_hidden,nl):       \n",
    "        super().__init__()\n",
    "        self.n_uchars = n_uchars\n",
    "        self.n_hidden = n_hidden\n",
    "        self.nl = nl # number of recurrent layers\n",
    "        self.emb = nn.Embedding(n_uchars,n_factors)\n",
    "        self.rnn = nn.LSTM(n_factors,n_hidden,nl,dropout=0.5)\n",
    "        self.w_out = nn.Linear(n_hidden,n_uchars)        \n",
    "        self.init_hidden(bs) #initiate state matrix h here\n",
    "        \n",
    "    def init_hidden(self, bs): \n",
    "        self.h = (V(torch.zeros(self.nl, bs, self.n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, self.n_hidden))) # we need this now because LSTM expects to be given both\n",
    "                                                   # the initial hidden state but also the cell state\n",
    "\n",
    "    def forward(self, cs):\n",
    "    # actual shape of cs: torch variable with shape (bptt oscillating, bs)\n",
    "        bs = cs[0].size(0)\n",
    "\n",
    "        # self.h.size(1) might be different from bs (reminder: h.size is (1,bs,n_hidden)\n",
    "        # as our last batch contains a lessser number of rows\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        inp = self.emb(cs)\n",
    "        outp,h = self.rnn(inp, self.h)\n",
    "        \n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.w_out(outp), dim=-1).view(-1, self.n_uchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 115, 1, 489166)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=512; bptt=10; n_fac=87; n_hidden=512\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharSeqLSTMRNN(md.nt, n_fac, bs,n_hidden,3)\n",
    "\n",
    "#Add SGDR instead of using constant lr\n",
    "lo = LayerOptimizer(optim.Adam, model, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(model, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, \n",
    "                on_cycle_end=on_end\n",
    "               )\n",
    "     ]\n",
    "# len(md.trn_dl): how often to reset. In this case it’s # of batches, so reset every epoch\n",
    "# on_cycle_end: function to save model at reset. Need 2 inputs arg: sched and cycle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fb7553c054474ea0796f075dedd480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      2.590059   2.336964  \n",
      "    1      2.012689   1.836091                                                 \n",
      "    2      1.792068   1.772297                                                 \n",
      "    3      1.742146   1.754016                                                 \n",
      "    4      1.686643   1.706246                                                 \n",
      "    5      1.62319    1.672655                                                 \n",
      "    6      1.586648   1.661755                                                 \n",
      "    7      1.630597   1.683238                                                 \n",
      "    8      1.616524   1.6627                                                   \n",
      "    9      1.58384    1.645871                                                 \n",
      "    10     1.537439   1.600161                                                 \n",
      "    11     1.488717   1.577381                                                 \n",
      "    12     1.443946   1.557848                                                 \n",
      "    13     1.411099   1.544896                                                 \n",
      "    14     1.3873     1.534149                                                 \n",
      "    15     1.511553   1.610655                                                 \n",
      "    16     1.524537   1.613975                                                 \n",
      "    17     1.501553   1.583105                                                 \n",
      "    18     1.47513    1.588668                                                 \n",
      "    19     1.451967   1.575931                                                 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.57593])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 20, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nhỏ hạnh cho nó cũng chẳng biết cho nó cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao c\n",
      "vợ chồng lon thì tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao\n",
      "Tiểu Long cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũn\n"
     ]
    }
   ],
   "source": [
    "sampl = 'tụi nhỏ '\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-bptt:])\n",
    "print(sampl)\n",
    "\n",
    "sampl = 'vợ chồng'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-bptt:])\n",
    "print(sampl)\n",
    "\n",
    "sampl = 'Tiểu Long'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-bptt:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vang lên trên chuyện gì cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho tao cũng chẳng biết cho \n"
     ]
    }
   ],
   "source": [
    "sampl = 'vang lên'\n",
    "for i in range(300):\n",
    "    sampl+= next_char(model,sampl[-bptt:])\n",
    "print(sampl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp,device=-1)\n",
    "    p = model(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]\n",
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tụi nó được!quý ròm - ngồi vừa bổng với đi !tùng đụng nhìn tiểu long tại mình, tay vẵ đúng bất tiếp tiểu long về phía sinh rả, chỉ không nhỏ hạnh biết được nên đây, ta 9i đạp” thằng mạnh ít câu có hai mông bị xíu mà, không như những ngắm đầu ẫm, bài r!- ừ, bè long nhìn mách! chẳng không, dăn hỏi tuốt qua em đáo ! - nhỏ hạnh cho hạnh mạnh là vậy tới ta” nhưng thâm chiếc. chỉ có biết về chú ?- trúng bị x\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('tụi n', 400))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oh shit! REDO! TODO: put cuda() and remove 'device' param in TEXT.numericalize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
